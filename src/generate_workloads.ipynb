{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "subgraph = 0\n",
    "B = 125_000_000 # BYTES\n",
    "\n",
    "out_name = f'traces/trace_{subgraph}'                                       # name of saved trace\n",
    "config_path = os.getcwd() + f'/topologies/final_topology_{subgraph}/'       # path to switch config files for topology\n",
    "data_path = 'data/reindexed.json'                                           # path to file containing topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num src: 5149 || num dests: 88\n"
     ]
    }
   ],
   "source": [
    "configs = os.listdir(config_path)\n",
    "\n",
    "with open(data_path,'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "nodes = {}\n",
    "for node in data['nodeList']:\n",
    "    nodes[node['id']] = node\n",
    "\n",
    "sources = [] # access\n",
    "destinations = [] # kernel or mixed \n",
    "\n",
    "for config in configs:\n",
    "    id = int(config.split('.')[0])\n",
    "\n",
    "    if nodes[id]['deviceLevel'] == 'Access':\n",
    "        sources.append(id)\n",
    "    else:\n",
    "        destinations.append(id) \n",
    "\n",
    "print(\"num src:\",len(sources), \"|| num dests:\",len(destinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOW_THROUGHPUT = B                     # BYTES PER SECOND\n",
    "SIMULATION_TIME = 1000000               # Ns\n",
    "PAIRS_PER_SRC = {'mu': 1, 'sigma': 0}   # NORMAL DIST\n",
    "MSG_SIZE = 50_000                       # BYTES\n",
    "PACKET_SIZE = 1400                      # BYTES\n",
    "BANDWIDTH = 10_000_000                  # BYTES\n",
    "PRIO_LEVELS = 3                         # QOS PRIORITIES\n",
    "\n",
    "s_to_ns = lambda x : int(x * math.pow(10,9))\n",
    "ns_to_s = lambda x : x * math.pow(10,-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOW_THROUGHPUT:1250000000__SIMULATION_TIME:1000000__PAIRS_PER_SRC:(1, 0)__MSG_SIZE:50000__PACKET_SIZE:1400__BANDWIDTH:10000000__PRIO_LEVELS:3\n"
     ]
    }
   ],
   "source": [
    "parameters = (f\"FLOW_THROUGHPUT:{FLOW_THROUGHPUT}__\"\n",
    "          f\"SIMULATION_TIME:{SIMULATION_TIME}__\"\n",
    "          f\"PAIRS_PER_SRC:{tuple(PAIRS_PER_SRC.values())}__\"\n",
    "          f\"MSG_SIZE:{MSG_SIZE}__\"\n",
    "          f\"PACKET_SIZE:{PACKET_SIZE}__\"\n",
    "          f\"BANDWIDTH:{BANDWIDTH}__\"\n",
    "          f\"PRIO_LEVELS:{PRIO_LEVELS}\")\n",
    "\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate flows\n",
    "flows = {}\n",
    "for src in sources:\n",
    "    num_pairs = int(random.normalvariate(**PAIRS_PER_SRC))\n",
    "    while num_pairs <= 0:\n",
    "        num_pairs = int(random.normalvariate(**PAIRS_PER_SRC))\n",
    "    \n",
    "    flows[src] = random.sample(sources, k=num_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_messages_for_flow(duration_ns):\n",
    "    total_bytes_for_duration = ns_to_s(duration_ns) * FLOW_THROUGHPUT\n",
    "\n",
    "    sizes = []\n",
    "\n",
    "    while sum(sizes) < total_bytes_for_duration:\n",
    "        sizes.append(int(random.expovariate(1/MSG_SIZE)))\n",
    "    \n",
    "    times = np.linspace(0, duration_ns, len(sizes))\n",
    "    times = [int(x) for x in times]\n",
    "\n",
    "    return times, sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5149 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5149/5149 [00:00<00:00, 9040.52it/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Generation Logic:\n",
    "        - For each source - while the current message time is less than the simulation time\n",
    "            - pick the next message time (exp dist)\n",
    "            - pick a random dest (uniform)\n",
    "            - pick a random message (size)\n",
    "            - split the message into packets based on packets size\n",
    "            - add packets accumulating transmission time (terminal -> switch)\n",
    "'''\n",
    "\n",
    "message_id = 0\n",
    "messages = []\n",
    "for src, pairs in tqdm(flows.items()):\n",
    "     for dst in pairs:\n",
    "        flow_messages = generate_messages_for_flow(SIMULATION_TIME)\n",
    "\n",
    "        for size, time in zip(*flow_messages):\n",
    "            tos = random.randint(0, PRIO_LEVELS-1)\n",
    "\n",
    "            messages.append({\n",
    "                'message_id': message_id,\n",
    "                'src': src,\n",
    "                'dst': dst,\n",
    "                'size': size,\n",
    "                'timestamp':time,\n",
    "                'tos': tos\n",
    "            })\n",
    "\n",
    "        message_id += 1\n",
    "\n",
    "messages = sorted(messages, key=lambda x:x['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133784/133784 [01:58<00:00, 1129.74it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_packet_id = 0\n",
    "\n",
    "f =  open(out_name+'_'+parameters, 'w')\n",
    "\n",
    "for msg in tqdm(messages):\n",
    "    message_id, src, dst, size, timestamp, tos = msg.values()\n",
    "\n",
    "    num_packets = math.ceil(size / PACKET_SIZE) # ceil -> padding last packet to always be PACKET_SIZE\n",
    "    \n",
    "    packet_time = timestamp\n",
    "    packets = []\n",
    "    for _ in range(num_packets):\n",
    "        packet_info = (\n",
    "            f\"{str(unique_packet_id)} \"\n",
    "            f\"{str(message_id)} \"\n",
    "            f\"{str(src)} \"\n",
    "            f\"{str(dst)} \"\n",
    "            f\"{str(PACKET_SIZE)} \"\n",
    "            f\"{str(packet_time)} \"\n",
    "            f\"{str(tos)}\\n\"\n",
    "        )\n",
    "\n",
    "        f.write(packet_info)\n",
    "\n",
    "        packet_time += PACKET_SIZE / BANDWIDTH\n",
    "        unique_packet_id += 1 \n",
    "\n",
    "f.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
